{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to your CSV files\n",
    "data_file_path = r'C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\data\\data.csv'\n",
    "variable_definitions_file_path = r'C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\data\\Xente_Variable_Definitions.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "try:\n",
    "    data = pd.read_csv(data_file_path)\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{data_file_path}' was not found.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preview:\n",
      "         TransactionId         BatchId       AccountId       SubscriptionId  \\\n",
      "0  TransactionId_76871   BatchId_36123  AccountId_3957   SubscriptionId_887   \n",
      "1  TransactionId_73770   BatchId_15642  AccountId_4841  SubscriptionId_3829   \n",
      "2  TransactionId_26203   BatchId_53941  AccountId_4229   SubscriptionId_222   \n",
      "3    TransactionId_380  BatchId_102363   AccountId_648  SubscriptionId_2185   \n",
      "4  TransactionId_28195   BatchId_38780  AccountId_4841  SubscriptionId_3829   \n",
      "\n",
      "        CustomerId CurrencyCode  CountryCode    ProviderId     ProductId  \\\n",
      "0  CustomerId_4406          UGX          256  ProviderId_6  ProductId_10   \n",
      "1  CustomerId_4406          UGX          256  ProviderId_4   ProductId_6   \n",
      "2  CustomerId_4683          UGX          256  ProviderId_6   ProductId_1   \n",
      "3   CustomerId_988          UGX          256  ProviderId_1  ProductId_21   \n",
      "4   CustomerId_988          UGX          256  ProviderId_4   ProductId_6   \n",
      "\n",
      "      ProductCategory    ChannelId   Amount  Value  TransactionStartTime  \\\n",
      "0             airtime  ChannelId_3   1000.0   1000  2018-11-15T02:18:49Z   \n",
      "1  financial_services  ChannelId_2    -20.0     20  2018-11-15T02:19:08Z   \n",
      "2             airtime  ChannelId_3    500.0    500  2018-11-15T02:44:21Z   \n",
      "3        utility_bill  ChannelId_3  20000.0  21800  2018-11-15T03:32:55Z   \n",
      "4  financial_services  ChannelId_2   -644.0    644  2018-11-15T03:34:21Z   \n",
      "\n",
      "   PricingStrategy  FraudResult  \n",
      "0                2            0  \n",
      "1                2            0  \n",
      "2                2            0  \n",
      "3                2            0  \n",
      "4                2            0  \n"
     ]
    }
   ],
   "source": [
    "# Preview the data\n",
    "print(\"Data Preview:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable definitions loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load variable definitions (optional)\n",
    "try:\n",
    "    variable_definitions = pd.read_csv(variable_definitions_file_path)\n",
    "    print(\"Variable definitions loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{variable_definitions_file_path}' was not found.\")\n",
    "    variable_definitions = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the dataset:\n",
      "Index(['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId',\n",
      "       'CurrencyCode', 'CountryCode', 'ProviderId', 'ProductId',\n",
      "       'ProductCategory', 'ChannelId', 'Amount', 'Value',\n",
      "       'TransactionStartTime', 'PricingStrategy', 'FraudResult'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the column names to check for 'FraudResult'\n",
    "print(\"Column names in the dataset:\")\n",
    "print(data.columns)\n",
    "\n",
    "# Step 1: Check if 'FraudResult' column exists\n",
    "if 'FraudResult' not in data.columns:\n",
    "    print(\"Error: The 'FraudResult' column is missing from the dataset.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define a proxy variable for categorizing users\n",
    "data['Risk_Category'] = data['FraudResult'].apply(lambda x: 'High Risk' if x == 1 else 'Low Risk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n",
      "                 CountryCode    Amount     Value  PricingStrategy  FraudResult\n",
      "CountryCode              NaN       NaN       NaN              NaN          NaN\n",
      "Amount                   NaN  1.000000  0.989692        -0.061931     0.557370\n",
      "Value                    NaN  0.989692  1.000000        -0.017020     0.566739\n",
      "PricingStrategy          NaN -0.061931 -0.017020         1.000000    -0.033821\n",
      "FraudResult              NaN  0.557370  0.566739        -0.033821     1.000000\n",
      "High Correlation Features: ['Amount', 'Value', 'FraudResult']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Select observable features that correlate with the fraud result variable\n",
    "# Convert categorical variables to numeric if necessary\n",
    "data_numeric = pd.get_dummies(data.select_dtypes(include=['number']), drop_first=True)  # Keep only numeric columns and convert dummies\n",
    "\n",
    "# Calculate the correlation matrix on numeric data only\n",
    "correlation_matrix = data_numeric.corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# Selecting features with high correlation with the target variable 'FraudResult'\n",
    "correlation_threshold = 0.3  # Adjust threshold as necessary\n",
    "high_corr_features = correlation_matrix.index[abs(correlation_matrix['FraudResult']) > correlation_threshold].tolist()\n",
    "print(f\"High Correlation Features: {high_corr_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns (using selected features)\n",
    "X = data[high_corr_features].drop(columns=['FraudResult', 'Risk_Category'], errors='ignore')  # Exclude target and proxy variable\n",
    "y = data['FraudResult']\n",
    "\n",
    "# Encode categorical variables if necessary\n",
    "X = pd.get_dummies(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1a: Split the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1b: Choose Models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to save models if it doesn't exist\n",
    "model_dir = r'C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\saved_models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n"
     ]
    }
   ],
   "source": [
    "# Step 1c: Train the Models\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    best_models[model_name] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n",
      "Best parameters for Random Forest: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Tuning Gradient Boosting...\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "print(\"Tuning Random Forest...\")\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), rf_param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_models['Random Forest'] = grid_search_rf.best_estimator_\n",
    "print(f\"Best parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
    "\n",
    "# Hyperparameter tuning for Gradient Boosting\n",
    "print(\"Tuning Gradient Boosting...\")\n",
    "grid_search_gb = GridSearchCV(GradientBoostingClassifier(), gb_param_grid, cv=5, scoring='roc_auc')\n",
    "grid_search_gb.fit(X_train, y_train)\n",
    "best_models['Gradient Boosting'] = grid_search_gb.best_estimator_\n",
    "print(f\"Best parameters for Gradient Boosting: {grid_search_gb.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.9979\n",
      "Precision: 0.4643\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.3881\n",
      "ROC-AUC: 0.9977\n",
      "Model saved to: C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\saved_models\\Logistic_Regression.pkl\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.9995\n",
      "Precision: 0.9688\n",
      "Recall: 0.7949\n",
      "F1 Score: 0.8732\n",
      "ROC-AUC: 0.9589\n",
      "Model saved to: C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\saved_models\\Decision_Tree.pkl\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9995\n",
      "Precision: 0.9688\n",
      "Recall: 0.7949\n",
      "F1 Score: 0.8732\n",
      "ROC-AUC: 0.9589\n",
      "Model saved to: C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\saved_models\\Random_Forest.pkl\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.9995\n",
      "Precision: 1.0000\n",
      "Recall: 0.7692\n",
      "F1 Score: 0.8696\n",
      "ROC-AUC: 0.9865\n",
      "Model saved to: C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\saved_models\\Gradient_Boosting.pkl\n"
     ]
    }
   ],
   "source": [
    "#  Model Evaluation\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = os.path.join(model_dir, f\"{model_name.replace(' ', '_')}.pkl\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"Model saved to: {model_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved to: C:\\Users\\hayyu.ragea\\AppData\\Local\\Programs\\Python\\Python312\\credit-scoring-model-bati-bank\\saved_models\\scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save the scaler for future use\n",
    "scaler_filename = os.path.join(model_dir, 'scaler.pkl')\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler saved to: {scaler_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
